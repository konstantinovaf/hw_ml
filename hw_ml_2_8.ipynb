{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преподаватель: Артур Сапрыкин\n",
    "Условие: Задача состоит в модификации кода градиентного спуска для задачи регрессии (ноутбук лекции - Gradient_descent.ipynb). Необходимо, чтобы ваш градиентный спуск мог решать задачи классификации, а именно линейной классификации и логистической регрессии.\n",
    "На всякий случай напомню, что код будет разный, поэтому жду от вас две функции градиентного спуска.\n",
    "Решение задачи можете найти в этой статье - https://dyakonov.org/2018/03/12/логистическая-функция-ошибки/. Там указан необходимый лосс и градиент\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets.samples_generator import make_regression \n",
    "import pylab\n",
    "from scipy import stats\n",
    "\n",
    "# https://dyakonov.org/2018/03/12/логистическая-функция-ошибки/\n",
    "\n",
    "# Гораздо понятнее статья\n",
    "# https://towardsdatascience.com/building-a-logistic-regression-in-python-301d27367c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# шаг алгоритма\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn.datasets.load_iris(return_X_y=False)\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data[:100, :] \n",
    "y = data.target[:100]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь всё тоже самое, только корректируем функцию потерь\n",
    "\n",
    "# Поясняю обозначения:\n",
    "# a -> hypothesis\n",
    "# a - y -> loss\n",
    "# logloss -> J\n",
    "# d logloss / d w  -> gradient\n",
    "\n",
    "\n",
    "def gradient_descent_2(alpha, x, y, numIterations):\n",
    "    \"\"\"\n",
    "    Функция реализует алгоритм градиентного спуска. На каждом шаге выводится значение функции потерь\n",
    "    \"\"\"\n",
    "    \n",
    "    m = x.shape[0] # 100\n",
    "    theta = np.ones(2) # [ 1.  1.] ВЕСА МОДЕЛИ!!!\n",
    "    x_transpose = x.transpose() # транспонированная матрица x\n",
    "    \n",
    "    for iter in range( 0, numIterations ):\n",
    "        hypothesis = np.dot(x, theta) # матричное произведение\n",
    "        \n",
    "        loss = hypothesis - y\n",
    "        J = np.sum(loss ** 2) / (2 * m)  # функция потерь\n",
    "        \n",
    "#         print( \"iter %s | J: %.3f\" % (iter, J) )\n",
    "        \n",
    "        gradient = np.dot(x_transpose, loss) / m     \n",
    "        \n",
    "        theta = theta - alpha * gradient  # update\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_for_classification (alpha, x, y, numIterations):\n",
    "   \n",
    "    theta = np.ones(4) # [ 1.  1.] ВЕСА МОДЕЛИ!!!\n",
    "    \n",
    "    for iter in range( 0, numIterations ):\n",
    "        hypothesis = 1 / (1 + np.exp(-x @ theta.T)) \n",
    "        \n",
    "        loss = hypothesis - y\n",
    "        \n",
    "        J = -y*np.log(hypothesis) - (1 - y)*np.log(1 - hypothesis) # функция потерь\n",
    "        \n",
    "#         print( \"iter %s | J: %.3f\" % (iter, J) )\n",
    "        \n",
    "        gradient = loss @ x        \n",
    "        theta = theta - alpha * gradient  # update\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Веса полученные в ходе расчета градиента\n",
    "theta = gradient_descent_for_classification(0.01, X, y, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.20753712, -2.80312838,  4.78238056,  2.76582937])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.63115321e-04, 8.42900509e-04, 3.79918170e-04, 1.47498407e-03,\n",
       "       1.39062347e-04, 2.70079945e-04, 5.20486673e-04, 3.92890996e-04,\n",
       "       2.03801890e-03, 7.79190043e-04, 1.04571102e-04, 8.06628894e-04,\n",
       "       7.21362178e-04, 3.14380150e-04, 6.62796392e-06, 1.77905763e-05,\n",
       "       3.98848286e-05, 2.15075345e-04, 1.88720701e-04, 1.49658103e-04,\n",
       "       6.30652874e-04, 2.61161145e-04, 3.32844654e-05, 2.74342394e-03,\n",
       "       3.37787211e-03, 1.94199428e-03, 1.10127868e-03, 2.33194226e-04,\n",
       "       1.91327831e-04, 1.59312957e-03, 1.86821593e-03, 4.21430419e-04,\n",
       "       3.29045861e-05, 1.41455730e-05, 1.02719768e-03, 1.63968232e-04,\n",
       "       6.23837785e-05, 1.18998777e-04, 9.55530518e-04, 3.48216074e-04,\n",
       "       1.50440659e-04, 7.88975795e-03, 5.45690068e-04, 1.44625804e-03,\n",
       "       1.33502100e-03, 1.25359970e-03, 1.83089492e-04, 6.91342987e-04,\n",
       "       1.17990903e-04, 3.22362776e-04, 9.99867206e-01, 9.99873001e-01,\n",
       "       9.99974086e-01, 9.99934700e-01, 9.99971051e-01, 9.99969095e-01,\n",
       "       9.99956587e-01, 9.97276867e-01, 9.99924832e-01, 9.99829364e-01,\n",
       "       9.99614359e-01, 9.99833590e-01, 9.99793137e-01, 9.99980679e-01,\n",
       "       9.97324308e-01, 9.99706822e-01, 9.99972405e-01, 9.99591017e-01,\n",
       "       9.99993952e-01, 9.99638059e-01, 9.99992786e-01, 9.99452918e-01,\n",
       "       9.99997664e-01, 9.99974618e-01, 9.99752166e-01, 9.99803668e-01,\n",
       "       9.99978929e-01, 9.99994517e-01, 9.99966205e-01, 9.95193968e-01,\n",
       "       9.99609033e-01, 9.99168689e-01, 9.99387970e-01, 9.99999170e-01,\n",
       "       9.99978326e-01, 9.99895913e-01, 9.99947030e-01, 9.99974667e-01,\n",
       "       9.99675125e-01, 9.99885615e-01, 9.99970523e-01, 9.99958747e-01,\n",
       "       9.99713266e-01, 9.97677543e-01, 9.99913122e-01, 9.99700365e-01,\n",
       "       9.99828292e-01, 9.99805330e-01, 9.85561222e-01, 9.99790718e-01])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = 1 / (1 + np.exp(-X @ theta.T))\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probab_threshold = 0.5\n",
    "\n",
    "y_predicted_cls = []\n",
    "\n",
    "for item in y_pred_proba:\n",
    "    if item >= probab_threshold:\n",
    "        y_predicted_cls.append(1)\n",
    "    else:\n",
    "        y_predicted_cls.append(0)\n",
    "\n",
    "y_predicted_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (y_predicted_cls == y).all().mean()\n",
    "accuracy\n",
    "# 100% точность то есть массивы совпадают"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
